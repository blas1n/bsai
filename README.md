# BSAI - Platform-oriented AI Agent Orchestrator

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

**BSAI** is an enterprise-grade AI Agent orchestrator platform. It's not just a simple agent, but a **platform with built-in LLMOps capabilities**.

## ğŸ¯ Key Features

### ğŸ¤– Multi-Interface Support
- **REST API**: RESTful interface for web frontends
- **WebSocket**: Real-time streaming responses
- **MCP (Model Context Protocol)**: Direct access for LLMs like Claude

### ğŸ”„ Multi-Vendor LLM Integration
Use multiple LLM vendors through a unified interface:
- OpenAI (GPT-4, GPT-3.5)
- Anthropic (Claude 3)
- Google (Gemini)
- Extensible for additional vendors

### ğŸ“Š LLMOps Platform Features
- **Centralized Prompt Store**: Git-style version control, rollback, change history
- **Cost Tracking**: Real-time token-level cost monitoring
- **Distributed Tracing**: Complete request tracing with OpenTelemetry
- **Experimentation Platform**: A/B testing and prompt quality evaluation
- **Security**: Automatic PII filtering, RBAC, audit logs

### ğŸ—ï¸ Production-Ready Architecture
- **100% Containerized**: Zero external dependencies, instant GitHub Codespaces execution
- High-performance async/await
- PostgreSQL + Redis
- Prometheus metrics
- Structured logging
- TDD/DDD-based development

## ğŸš€ Quick Start

### ğŸ¯ Easiest Way: GitHub Codespaces (Recommended!)

**No installation required!**

1. [Create Codespace from this repository](https://github.com/yourusername/bsai/codespaces)
2. Wait 3-5 minutes (automatic setup)
3. In terminal: `uvicorn src.agent_platform.main:app --reload`
4. Access automatically forwarded port 8000 in browser!

Details: [GitHub Codespaces Guide](docs/deployment/codespaces.md)

### ğŸ’» Local Development: Docker Compose

**Prerequisites**: Docker Desktop only

```bash
# 1. Clone & setup
git clone https://github.com/yourusername/bsai.git
cd bsai
cp .env.example .env
# Add your API keys to .env

# 2. Start full stack (PostgreSQL + Redis + Dev environment)
docker compose -f docker-compose.dev.yml up -d

# 3. Access dev container
docker compose exec app bash

# 4. Run server
uvicorn src.agent_platform.main:app --reload --host 0.0.0.0
```

### ğŸ’ VS Code Dev Containers (Recommended!)

**Prerequisites**: VS Code + Docker Desktop + Dev Containers extension

```bash
# 1. Clone & open
git clone https://github.com/yourusername/bsai.git
code bsai

# 2. In VS Code: F1 â†’ "Dev Containers: Reopen in Container"
# 3. Automatic build and all services start
# 4. Start developing immediately!
```

All setup is done automatically! ğŸ‰

API Documentation: [http://localhost:8000/api/docs](http://localhost:8000/api/docs)

## ğŸ“– Documentation

### Core Documentation
- [Installation Guide](docs/guides/installation.md) - Container-based installation
- [GitHub Codespaces Guide](docs/deployment/codespaces.md) - How to use Codespaces
- [Docker Guide](DOCKER_GUIDE.md) - **Two Dockerfiles explained**
- [Containerization Strategy](CONTAINERIZATION.md) - 100% containerization details
- [Architecture Overview](docs/architecture/overview.md) - System architecture

### Full Documentation
Full documentation: [https://bsai.readthedocs.io](https://bsai.readthedocs.io)

Build docs locally:
```bash
pip install -e ".[docs]"
mkdocs serve
```

## ğŸ›ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Interfaces Layer                       â”‚
â”‚   REST API â”‚ WebSocket â”‚ MCP Server                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Core Layer                            â”‚
â”‚  Orchestrator â”‚ Planner â”‚ Executor â”‚ Memory â”‚ Tools    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LLM Abstraction                        â”‚
â”‚   Registry â”‚ Providers (OpenAI, Claude, Gemini, ...)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Platform Layer                          â”‚
â”‚  Prompts â”‚ Trace â”‚ Cost â”‚ Experiments â”‚ Security        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Infrastructure Layer                      â”‚
â”‚    PostgreSQL â”‚ Redis â”‚ OTLP â”‚ Prometheus               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Structure

```
bsai/
â”œâ”€â”€ src/agent_platform/          # Main source code
â”‚   â”œâ”€â”€ core/                    # Agent core logic
â”‚   â”‚   â”œâ”€â”€ llm/                # LLM abstraction layer
â”‚   â”‚   â”œâ”€â”€ orchestrator/       # Task planning & execution
â”‚   â”‚   â”œâ”€â”€ memory/             # Context management
â”‚   â”‚   â””â”€â”€ tools/              # Tool registry
â”‚   â”œâ”€â”€ platform/               # Platform features
â”‚   â”‚   â”œâ”€â”€ prompt_store/       # Prompt versioning
â”‚   â”‚   â”œâ”€â”€ trace/              # Distributed tracing
â”‚   â”‚   â”œâ”€â”€ cost/               # Cost tracking
â”‚   â”‚   â”œâ”€â”€ experiments/        # A/B testing
â”‚   â”‚   â””â”€â”€ security/           # Security & PII filtering
â”‚   â”œâ”€â”€ interfaces/             # External interfaces
â”‚   â”‚   â”œâ”€â”€ api/               # FastAPI routers
â”‚   â”‚   â””â”€â”€ mcp/               # MCP server
â”‚   â”œâ”€â”€ infrastructure/         # Infrastructure layer
â”‚   â”‚   â”œâ”€â”€ database/          # PostgreSQL
â”‚   â”‚   â”œâ”€â”€ cache/             # Redis
â”‚   â”‚   â””â”€â”€ messaging/         # Event bus (future)
â”‚   â””â”€â”€ domain/                # Domain models
â”œâ”€â”€ tests/                     # Tests
â”‚   â”œâ”€â”€ unit/                 # Unit tests
â”‚   â”œâ”€â”€ integration/          # Integration tests
â”‚   â””â”€â”€ e2e/                  # E2E tests
â”œâ”€â”€ docs/                     # MkDocs documentation
â””â”€â”€ migrations/               # Alembic migrations
```

## ğŸ’¡ Use Cases

### 1. Customer Support Agent
```python
response = await agent.execute(
    message="Customer is asking about refund policy",
    tools=["knowledge_base", "ticket_system", "escalation"]
)
```

### 2. Code Review Assistant
```python
response = await agent.execute(
    message="Review this pull request",
    context={"repo": "myorg/myrepo", "pr": 123},
    tools=["git", "linter", "security_scanner"]
)
```

### 3. Research Agent
```python
response = await agent.execute(
    message="Research latest trends in quantum computing",
    tools=["web_search", "paper_search", "summarization"]
)
```

## ğŸ”§ Technology Stack

| Component | Technology | Purpose |
|-----------|-----------|---------|
| **Framework** | FastAPI | Async web framework |
| **Database** | PostgreSQL | Primary datastore |
| **Cache** | Redis | Session & caching |
| **LLM SDK** | LiteLLM | Multi-provider abstraction |
| **Tracing** | OpenTelemetry | Distributed tracing |
| **Metrics** | Prometheus | Monitoring |
| **Logging** | Structlog | Structured JSON logs |
| **Testing** | pytest | Test framework |
| **Docs** | MkDocs Material | Documentation |
| **Package Manager** | UV | Fast dependency management |

## ğŸ› ï¸ Development

### Setup Development Environment

```bash
# Install development dependencies
pip install -e ".[dev]"

# Install pre-commit hooks
pre-commit install

# Run tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Lint
ruff check src/
black src/

# Type check
mypy src/
```

### Development Philosophy

#### 1ï¸âƒ£ TDD (Test-Driven Development)
Write tests first for all features.

```python
# 1. Write test
def test_prompt_versioning():
    prompt = create_prompt(name="test", content="v1")
    assert prompt.version == 1

# 2. Implement
def create_prompt(name, content):
    return Prompt(name=name, content=content, version=1)

# 3. Refactor
```

#### 2ï¸âƒ£ DDD (Documentation-Driven Development)
Write design documents first, then implement.

- Architecture: `docs/architecture/`
- API Specs: `docs/api/`
- Guides: `docs/guides/`

#### 3ï¸âƒ£ Clean Architecture
- Dependency inversion
- Separation of concerns
- Testable components

### Project Structure Principles

```
interfaces â†’ core â†’ platform â†’ infrastructure
     â†“        â†“        â†“
  domain â† domain â† domain
```

## ğŸ“Š Observability

### Metrics (Prometheus)

```bash
# Metrics endpoint
curl http://localhost:8000/metrics
```

Key metrics:
- `llm_calls_total` - Total LLM API calls
- `llm_latency_seconds` - LLM call latency
- `llm_tokens_used` - Token consumption
- `llm_cost_total` - Total cost in USD

### Tracing (OpenTelemetry)

All requests are automatically traced:

```
agent.execute (123ms)
  â”œâ”€ planner.plan (45ms)
  â”‚   â””â”€ llm.chat_completion (40ms)
  â”œâ”€ executor.execute (65ms)
  â”‚   â”œâ”€ tool.web_search (30ms)
  â”‚   â””â”€ llm.chat_completion (30ms)
  â””â”€ memory.store (3ms)
```

### Logging (Structlog)

Structured JSON logs:

```json
{
  "event": "llm_call_completed",
  "timestamp": "2025-10-05T12:34:56.789Z",
  "trace_id": "a1b2c3d4...",
  "provider": "openai",
  "model": "gpt-4",
  "tokens": 1234,
  "cost": 0.0246,
  "latency_ms": 850
}
```

## ğŸ” Security

### Authentication
- JWT-based authentication
- API key support
- OAuth2 integration (planned)

### PII Protection
Automatic detection and masking:

```python
input: "My email is john@example.com"
output: "My email is ***@***"
```

### Access Control
- Role-based access control (RBAC)
- Resource-level permissions
- Audit logging

## ğŸ§ª Testing

```bash
# Run all tests
pytest

# Run specific test file
pytest tests/unit/core/test_llm_base.py

# Run with coverage
pytest --cov=src --cov-report=html

# Run only fast tests
pytest -m "not slow"
```

Test structure:
- **Unit tests**: Test individual components
- **Integration tests**: Test component interactions
- **E2E tests**: Test full workflows

## ğŸ“ˆ Roadmap

### Phase 1: MVP (Current)
- [x] Project structure
- [x] Core architecture design
- [x] Database schema design
- [x] FastAPI skeleton
- [x] Basic LLM abstraction
- [ ] OpenAI provider implementation
- [ ] Basic orchestrator
- [ ] Cost tracker

### Phase 2: Platform Features
- [ ] Full prompt versioning
- [ ] Experiment framework
- [ ] Advanced tracing
- [ ] MCP server
- [ ] PII filtering

### Phase 3: Production Ready
- [ ] Performance optimization
- [ ] Monitoring dashboard
- [ ] Auto-scaling support
- [ ] Load testing
- [ ] Production deployment

### Phase 4: Enterprise
- [ ] Multi-tenancy
- [ ] SSO integration
- [ ] Advanced RBAC
- [ ] Compliance features
- [ ] SLA monitoring

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](docs/guides/contributing.md) for details.

### Getting Started

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Write tests for your changes
4. Implement your changes
5. Run tests (`pytest`)
6. Commit with conventional commits (`git commit -m "feat: add amazing feature"`)
7. Push to your fork (`git push origin feature/amazing-feature`)
8. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Inspired by [Woowa Brothers' LLM Platform Architecture](https://techblog.woowahan.com/)
- Built with [FastAPI](https://fastapi.tiangolo.com)
- Powered by [OpenTelemetry](https://opentelemetry.io)

## ğŸ“ Contact & Support

- **Documentation**: [https://bsai.readthedocs.io](https://bsai.readthedocs.io)
- **Issues**: [GitHub Issues](https://github.com/yourusername/bsai/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/bsai/discussions)

---

**Built with â¤ï¸ for the future of AI Agent platforms**
